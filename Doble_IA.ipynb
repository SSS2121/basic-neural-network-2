{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "authorship_tag": "ABX9TyNb6C1nndsj7skXPwsPGtIf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SSS2121/basic-neural-network-2/blob/main/Doble_IA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "7Wxa6npPligM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2091c3be-b89e-4c84-ec6f-fc469734bbb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jax/_src/cloud_tpu_init.py:86: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#!pip install tensorflow\n",
        "from PIL import Image\n",
        "import io\n",
        "import numpy as np\n",
        "import tensorflow as ts\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import datasets\n",
        "cargados = False\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
        "\n",
        "# imagenes al 128x128\n",
        "train_images = ts.image.resize(train_images, (64, 64))\n",
        "test_images = ts.image.resize(test_images, (64, 64))\n",
        "\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deteccion de imagenes"
      ],
      "metadata": {
        "id": "CLRbG6IMlj3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Primer modelo de IA (entendimiento de imagenes)\n",
        "model_1 = ts.keras.models.Sequential([\n",
        "  ts.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(64, 64, 3)), # Changed input_shape to 64x64\n",
        "  ts.keras.layers.MaxPooling2D((2, 2)),\n",
        "  ts.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "  ts.keras.layers.MaxPooling2D((2, 2)),\n",
        "  ts.keras.layers.Flatten(),\n",
        "  ts.keras.layers.Dense(64, activation='relu'),\n",
        "  ts.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "def Graficos():\n",
        "  model_1.compile(\n",
        "    optimizer='Adam',\n",
        "    loss = ts.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy']\n",
        "  )\n",
        "\n",
        "  model_1.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
        "print(\"modelo listo\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHSsMSckmA2i",
        "outputId": "58897fc6-dbe1-4200-862b-7dd7f2733a61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "modelo listo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cambio de numeros"
      ],
      "metadata": {
        "id": "Snq6CdkompYx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Segundo modelo de IA (Cambio de celcius a farehei)\n",
        "Cel = np.array([ -150,-149,-148,-147,-146,-145,-144,-143,-142,-141,\n",
        "-140,-139,-138,-137,-136,-135,-134,-133,-132,-131,\n",
        "-130,-129,-128,-127,-126,-125,-124,-123,-122,-121,\n",
        "-120,-119,-118,-117,-116,-115,-114,-113,-112,-111,\n",
        "-110,-109,-108,-107,-106,-105,-104,-103,-102,-101,\n",
        "-100,-99,-98,-97,-96,-95,-94,-93,-92,-91,\n",
        "-90,-89,-88,-87,-86,-85,-84,-83,-82,-81,\n",
        "-80,-79,-78,-77,-76,-75,-74,-73,-72,-71,\n",
        "-70,-69,-68,-67,-66,-65,-64,-63,-62,-61,\n",
        "-60,-59,-58,-57,-56,-55,-54,-53,-52,-51,\n",
        "-50,-49,-48,-47,-46,-45,-44,-43,-42,-41,\n",
        "-40,-39,-38,-37,-36,-35,-34,-33,-32,-31,\n",
        "-30,-29,-28,-27,-26,-25,-24,-23,-22,-21,\n",
        "-20,-19,-18,-17,-16,-15,-14,-13,-12,-11,\n",
        "-10,-9,-8,-7,-6,-5,-4,-3,-2,-1,\n",
        "0,1,2,3,4,5,6,7,8,9,\n",
        "10,11,12,13,14,15,16,17,18,19,\n",
        "20,21,22,23,24,25,26,27,28,29,\n",
        "30,31,32,33,34,35,36,37,38,39,\n",
        "40,41,42,43,44,45,46,47,48,49,\n",
        "50,51,52,53,54,55,56,57,58,59,\n",
        "60,61,62,63,64,65,66,67,68,69,\n",
        "70,71,72,73,74,75,76,77,78,79,\n",
        "80,81,82,83,84,85,86,87,88,89,\n",
        "90,91,92,93,94,95,96,97,98,99,\n",
        "100,101,102,103,104,105,106,107,108,109,\n",
        "110,111,112,113,114,115,116,117,118,119,\n",
        "120,121,122,123,124,125,126,127,128,129,\n",
        "130,131,132,133,134,135,136,137,138,139,\n",
        "140,141,142,143,144,145,146,147,148,149,\n",
        "150,151,152,153,154,155,156,157,158,159,\n",
        "160,161,162,163,164,165,166,167,168,169,\n",
        "170,171,172,173,174,175,176,177,178,179,\n",
        "180,181,182,183,184,185,186,187,188,189,\n",
        "190,191,192,193,194,195,196,197,198,199,\n",
        "200,201,202,203,204,205,206,207,208,209,\n",
        "210,211,212,213,214,215,216,217,218,219,\n",
        "220,221,222,223,224,225,226,227,228,229,\n",
        "230,231,232,233,234,235,236,237,238,239,\n",
        "240,241,242,243,244,245,246,247,248,249], dtype=float)\n",
        "\n",
        "Fah = np.array([-238,-236.2,-234.4,-232.6,-230.8,-229,-227.2,-225.4,-223.6,-221.8,\n",
        "-220,-218.2,-216.4,-214.6,-212.8,-211,-209.2,-207.4,-205.6,-203.8,\n",
        "-202,-200.2,-198.4,-196.6,-194.8,-193,-191.2,-189.4,-187.6,-185.8,\n",
        "-184,-182.2,-180.4,-178.6,-176.8,-175,-173.2,-171.4,-169.6,-167.8,\n",
        "-166,-164.2,-162.4,-160.6,-158.8,-157,-155.2,-153.4,-151.6,-149.8,\n",
        "-148,-146.2,-144.4,-142.6,-140.8,-139,-137.2,-135.4,-133.6,-131.8,\n",
        "-130,-128.2,-126.4,-124.6,-122.8,-121,-119.2,-117.4,-115.6,-113.8,\n",
        "-112,-110.2,-108.4,-106.6,-104.8,-103,-101.2,-99.4,-97.6,-95.8,\n",
        "-94,-92.2,-90.4,-88.6,-86.8,-85,-83.2,-81.4,-79.6,-77.8,\n",
        "-76,-74.2,-72.4,-70.6,-68.8,-67,-65.2,-63.4,-61.6,-59.8,\n",
        "-58,-56.2,-54.4,-52.6,-50.8,-49,-47.2,-45.4,-43.6,-41.8,\n",
        "-40,-38.2,-36.4,-34.6,-32.8,-31,-29.2,-27.4,-25.6,-23.8,\n",
        "-22,-20.2,-18.4,-16.6,-14.8,-13,-11.2,-9.4,-7.6,-5.8,\n",
        "-4,-2.2,-0.4,1.4,3.2,5,6.8,8.6,10.4,12.2,\n",
        "14,15.8,17.6,19.4,21.2,23,24.8,26.6,28.4,30.2,\n",
        "32,33.8,35.6,37.4,39.2,41,42.8,44.6,46.4,48.2,\n",
        "50,51.8,53.6,55.4,57.2,59,60.8,62.6,64.4,66.2,\n",
        "68,69.8,71.6,73.4,75.2,77,78.8,80.6,82.4,84.2,\n",
        "86,87.8,89.6,91.4,93.2,95,96.8,98.6,100.4,102.2,\n",
        "104,105.8,107.6,109.4,111.2,113,114.8,116.6,118.4,120.2,\n",
        "122,123.8,125.6,127.4,129.2,131,132.8,134.6,136.4,138.2,\n",
        "140,141.8,143.6,145.4,147.2,149,150.8,152.6,154.4,156.2,\n",
        "158,159.8,161.6,163.4,165.2,167,168.8,170.6,172.4,174.2,\n",
        "176,177.8,179.6,181.4,183.2,185,186.8,188.6,190.4,192.2,\n",
        "194,195.8,197.6,199.4,201.2,203,204.8,206.6,208.4,210.2,\n",
        "212,213.8,215.6,217.4,219.2,221,222.8,224.6,226.4,228.2,\n",
        "230,231.8,233.6,235.4,237.2,239,240.8,242.6,244.4,246.2,\n",
        "248,249.8,251.6,253.4,255.2,257,258.8,260.6,262.4,264.2,\n",
        "266,267.8,269.6,271.4,273.2,275,276.8,278.6,280.4,282.2,\n",
        "284,285.8,287.6,289.4,291.2,293,294.8,296.6,298.4,300.2,\n",
        "302,303.8,305.6,307.4,309.2,311,312.8,314.6,316.4,318.2,\n",
        "320,321.8,323.6,325.4,327.2,329,330.8,332.6,334.4,336.2,\n",
        "338,339.8,341.6,343.4,345.2,347,348.8,350.6,352.4,354.2,\n",
        "356,357.8,359.6,361.4,363.2,365,366.8,368.6,370.4,372.2,\n",
        "374,375.8,377.6,379.4,381.2,383,384.8,386.6,388.4,390.2,\n",
        "392,393.8,395.6,397.4,399.2,401,402.8,404.6,406.4,408.2,\n",
        "410,411.8,413.6,415.4,417.2,419,420.8,422.6,424.4,426.2,\n",
        "428,429.8,431.6,433.4,435.2,437,438.8,440.6,442.4,444.2,\n",
        "446,447.8,449.6,451.4,453.2,455,456.8,458.6,460.4,462.2,\n",
        "464,465.8,467.6,469.4,471.2,473,474.8,476.6,478.4,480.2], dtype=float)\n",
        "\n",
        "capas = ts.keras.layers.Dense(units=3, input_shape=[1], activation='relu')\n",
        "oculta1 = ts.keras.layers.Dense(units=3, activation='relu')\n",
        "oculta2 = ts.keras.layers.Dense(units=3, activation='relu')\n",
        "oculta3 = ts.keras.layers.Dense(units=3, activation='relu')\n",
        "oculta4 = ts.keras.layers.Dense(units=3, activation='relu')\n",
        "Salida = ts.keras.layers.Dense(units=1, activation='linear')\n",
        "modelo_2 = ts.keras.Sequential([capas,oculta1, oculta2, oculta3,oculta4,Salida])\n",
        "\n",
        "def Numeros():\n",
        "  global Cel\n",
        "  global Fah\n",
        "  modelo_2.compile(optimizer=ts.keras.optimizers.Adam(0.1), loss='mean_squared_error')\n",
        "  print(\"Entrenando el modelo...\")\n",
        "  modelo_2.fit( Cel, Fah, epochs=1000, verbose=False)\n",
        "  print(\"Modelo entrenado!\")"
      ],
      "metadata": {
        "id": "CRQ4A5M6mtxJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7bc649f-c993-4bd5-a3bd-2224bd98119e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Load_models():\n",
        "  global cargados\n",
        "  if cargados == False:\n",
        "    Graficos()\n",
        "    Numeros()\n",
        "    cargados = True\n",
        "    return cargados\n",
        "  else:\n",
        "    return cargados"
      ],
      "metadata": {
        "id": "0qNX89O8xJAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Subir_imagen():\n",
        "  from google.colab import files\n",
        "  uploaded = files.upload()\n",
        "  return uploaded"
      ],
      "metadata": {
        "id": "LQ2M3TXX1Xfq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def Mostra_imagen(uploaded_files):\n",
        "\n",
        "  for fn in uploaded_files.keys():\n",
        "    # Abre la imagen\n",
        "    img = Image.open(io.BytesIO(uploaded_files[fn]))\n",
        "    # Redimensiona la imagen a 128 píxeles\n",
        "    img = img.resize((64, 64))\n",
        "    # Convierte la imagen a un array de numpy y normaliza los valores de píxeles\n",
        "    img_array = np.array(img) / 255.0\n",
        "    # Añade una dimensión extra para el 'batch' (el modelo espera un batch de imágenes)\n",
        "    img_array = np.expand_dims(img_array, axis=0);\n",
        "\n",
        "    # Haz la predicción\n",
        "    predictions = model_1.predict(img_array)\n",
        "    predicted_label = np.argmax(predictions[0])\n",
        "\n",
        "    # Define los nombres de las clases (basados en CIFAR-10)\n",
        "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "    # Muestra la imagen y la predicción\n",
        "    plt.figure()\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Predicción: {class_names[predicted_label]} ({predicted_label})\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    print(f\"El modelo predice: {class_names[predicted_label]}\")"
      ],
      "metadata": {
        "id": "GylsW6-q1pUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Encontrar_num():\n",
        "  num_input = float(input(\"Numero :\"))\n",
        "  Resultado = modelo_2.predict(np.array([[num_input]], dtype=float))\n",
        "  print(\"El resultado es: \" + str(Resultado) + \"F\")"
      ],
      "metadata": {
        "id": "rrJ2ZUJA6sBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "  if cargados == False:\n",
        "    Load_models()\n",
        "\n",
        "  des = input(\"1, 2, 3, 4: \")\n",
        "  if des == \"1\":\n",
        "    uploaded_files = Subir_imagen()\n",
        "    Mostra_imagen(uploaded_files)\n",
        "\n",
        "  elif des == \"2\":\n",
        "    Encontrar_num()\n",
        "\n",
        "  elif des == \"3\":\n",
        "    cargados = False\n",
        "    print(\"Modelo reseteado y cargandose nuevamente\")\n",
        "  elif des == \"4\":\n",
        "    break\n",
        "  else:\n",
        "    print(\"Opcion no valida\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MY1YZYust86B",
        "outputId": "170be94f-a055-4c0c-8d8c-24c8ef98bb09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 105ms/step - accuracy: 0.3539 - loss: 1.7771 - val_accuracy: 0.4933 - val_loss: 1.4009\n",
            "Epoch 2/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 105ms/step - accuracy: 0.5368 - loss: 1.3030 - val_accuracy: 0.5689 - val_loss: 1.2087\n",
            "Epoch 3/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 105ms/step - accuracy: 0.5883 - loss: 1.1686 - val_accuracy: 0.6064 - val_loss: 1.1159\n",
            "Epoch 4/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 105ms/step - accuracy: 0.6267 - loss: 1.0559 - val_accuracy: 0.6194 - val_loss: 1.1043\n",
            "Epoch 5/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 105ms/step - accuracy: 0.6581 - loss: 0.9700 - val_accuracy: 0.6253 - val_loss: 1.0688\n",
            "Epoch 6/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 105ms/step - accuracy: 0.6808 - loss: 0.9194 - val_accuracy: 0.6265 - val_loss: 1.0794\n",
            "Epoch 7/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 105ms/step - accuracy: 0.6981 - loss: 0.8673 - val_accuracy: 0.6456 - val_loss: 1.0378\n",
            "Epoch 8/10\n",
            "\u001b[1m   1/1563\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:18\u001b[0m 89ms/step - accuracy: 0.7812 - loss: 0.7748"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install tensorflowjs"
      ],
      "metadata": {
        "id": "6nYp0ionhYm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!tensorflowjs_converter --input_format keras Modelo.h5 Carpeta_salida/"
      ],
      "metadata": {
        "id": "wDkQULzRiw-l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}